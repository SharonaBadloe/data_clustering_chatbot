{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "add6afb5-8f79-4474-84ed-cca0696dc842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114703e81881431098aefa9b72c6f133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:42:44 INFO: Downloading default packages for language: en (English)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3b20f2fb624ef086b4a0d8c326f012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading http://nlp.stanford.edu/software/stanza/1.2.2/en/default.zip:   0%|          | 0.00/412M [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:52:11 INFO: Finished downloading models and saved to C:\\Users\\Shark\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from dframcy import DframCy\n",
    "\n",
    "import stanza\n",
    "stanza.download('en')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "StopWords = stopwords.words('english')\n",
    "\n",
    "import string \n",
    "punct = string.punctuation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038c8fb-cc72-4dcf-92a1-ee622a50e829",
   "metadata": {},
   "source": [
    "## Loading the preprocessed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09c20c46-ca91-4a07-9c96-95c1822b7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open filtered dataframe\n",
    "\n",
    "path = \"data/cleaned_dataframe.csv\"\n",
    "filtered_df = pd.read_csv(path)\n",
    "\n",
    "# remove unwanted columns\n",
    "filtered_df.drop(columns = ['sentences', 'Unnamed: 0'], inplace=True)\n",
    "filtered_df.head(10)\n",
    "\n",
    "# get sentences into string for spacy\n",
    "instances = filtered_df['raw_sentences'].tolist()\n",
    "joined_instances = ' '.join(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "994037e8-517d-4e25-9613-9b522368a101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@115712 Can you please send us a private message , so that I can gain further details about your account ? .',\n",
       " '@115715 Please send me a private message so that I can send you the link to access your account .',\n",
       " \"@115714 whenever I contact customer support , they tell me I have shortcode enabled on my account , but I have never in the 4 years I 've tried https://t.co/0G98RtNxPK .\",\n",
       " '@Ask_Spectrum Would you like me to email you a copy of one since Spectrum is not updating your training ? .',\n",
       " '@Ask_Spectrum',\n",
       " 'The correct way to do it is via an OCS Account Takeover and email Consent Form it does not need to be done in a local office .',\n",
       " '@115716',\n",
       " 'The information pertaining to the account assumption is correct .',\n",
       " 'This does need to be done at a local outlet wit ... https://t.co/P7XCmTzPQj .',\n",
       " \"actually that 's a broken link you sent me and incorrect information https://t.co/V4yfrHR8VI .\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319cb438-62b0-45cc-b80b-865557393c58",
   "metadata": {},
   "source": [
    "# Collecting data statistics \n",
    "\n",
    "Here I collect some explorative statistics on the data and save them into a a format that can easily be visualized.\n",
    "The following statistics are extracted:\n",
    "- 20 most common words (function words + interpunction not included)\n",
    "- Distribution of POS-tags\n",
    "- Distribution of Named Entity tags\n",
    "- Sentiment analysis distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e2b8099-d7d9-4a74-81d0-e3ee40459f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>token_start</th>\n",
       "      <th>token_end</th>\n",
       "      <th>token_pos_</th>\n",
       "      <th>token_tag_</th>\n",
       "      <th>token_dep_</th>\n",
       "      <th>token_head</th>\n",
       "      <th>token_ent_type_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>npadvmod</td>\n",
       "      <td>send</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>AUX</td>\n",
       "      <td>MD</td>\n",
       "      <td>aux</td>\n",
       "      <td>send</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>send</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>please</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>UH</td>\n",
       "      <td>intj</td>\n",
       "      <td>send</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>send</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>send</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59752</th>\n",
       "      <td>just</td>\n",
       "      <td>300549</td>\n",
       "      <td>300553</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>'re</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59753</th>\n",
       "      <td>a</td>\n",
       "      <td>300554</td>\n",
       "      <td>300555</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>tweet</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59754</th>\n",
       "      <td>tweet</td>\n",
       "      <td>300556</td>\n",
       "      <td>300561</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>npadvmod</td>\n",
       "      <td>away</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59755</th>\n",
       "      <td>away</td>\n",
       "      <td>300562</td>\n",
       "      <td>300566</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>'re</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59756</th>\n",
       "      <td>.</td>\n",
       "      <td>300567</td>\n",
       "      <td>300568</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>'re</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59757 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      token_text  token_start  token_end token_pos_ token_tag_ token_dep_  \\\n",
       "0        @115712            0          7      PROPN        NNP   npadvmod   \n",
       "1            Can            8         11        AUX         MD        aux   \n",
       "2            you           12         15       PRON        PRP      nsubj   \n",
       "3         please           16         22       INTJ         UH       intj   \n",
       "4           send           23         27       VERB         VB       ROOT   \n",
       "...          ...          ...        ...        ...        ...        ...   \n",
       "59752       just       300549     300553        ADV         RB     advmod   \n",
       "59753          a       300554     300555        DET         DT        det   \n",
       "59754      tweet       300556     300561       NOUN         NN   npadvmod   \n",
       "59755       away       300562     300566        ADV         RB     advmod   \n",
       "59756          .       300567     300568      PUNCT          .      punct   \n",
       "\n",
       "      token_head token_ent_type_  \n",
       "0           send                  \n",
       "1           send                  \n",
       "2           send                  \n",
       "3           send                  \n",
       "4           send                  \n",
       "...          ...             ...  \n",
       "59752        're                  \n",
       "59753      tweet                  \n",
       "59754       away                  \n",
       "59755        're                  \n",
       "59756        're                  \n",
       "\n",
       "[59757 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open text in Dframcy module \n",
    "dframcy = DframCy(nlp)\n",
    "doc = dframcy.nlp(joined_instances)\n",
    "\n",
    "# create dataframe with dFramcy features\n",
    "dframcy_df = dframcy.to_dataframe(doc)\n",
    "\n",
    "# display Dframcy dataframe\n",
    "dframcy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e0131a-b559-4662-a6cd-c933e6d2d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect needed columns to list\n",
    "tokens = dframcy_df['token_text'].tolist()\n",
    "pos = dframcy_df['token_pos_'].tolist()\n",
    "ents = dframcy_df['token_ent_type_'].tolist()\n",
    "\n",
    "# count data statistics\n",
    "word_freq = Counter(list(tokens))\n",
    "pos_freq = Counter(list(pos))\n",
    "ent_freq = Counter(list(ents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "539b2493-59e9-466a-aa96-c9996f6109f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from word frequency dict\n",
    "for word in StopWords:\n",
    "    if word in word_freq:\n",
    "        del word_freq[word]\n",
    "        \n",
    "# remove punctuation from word frequency dict\n",
    "for p in punct:\n",
    "    if p in word_freq:\n",
    "        del word_freq[p]\n",
    "        \n",
    "# keep only 20 most frequent words\n",
    "most_common = word_freq.most_common(20)\n",
    "\n",
    "common_words = []\n",
    "common_counts = []\n",
    "\n",
    "for item in most_common:\n",
    "    common_words.append(item[0])\n",
    "    common_counts.append(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c1aa262-78c0-4945-ab59-3d57519ad6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequency counts into dataframe \n",
    "\n",
    "# word freqs\n",
    "d = {'word': common_words, 'count': common_counts}\n",
    "word_df = pd.DataFrame(d)\n",
    "\n",
    "# pos freqs\n",
    "keys = list(pos_freq.keys())\n",
    "vals = list(pos_freq.values())\n",
    "d = {'pos': keys, 'count': vals}\n",
    "pos_df = pd.DataFrame(d)\n",
    "\n",
    "# ent freqs\n",
    "keys = list(ent_freq.keys())\n",
    "vals = list(ent_freq.values())\n",
    "d = {'ent': keys, 'count': vals}\n",
    "ent_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39f1958d-3449-4cf4-a6ba-1c42b5ae6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save frequency dicts to file for visualization\n",
    "\n",
    "word_df.to_excel(\"data/word_freq.xlsx\", header=False)\n",
    "pos_df.to_excel(\"data/pos_freq.xlsx\", header=False)\n",
    "ent_df.to_excel(\"data/ent_freq.xlsx\", header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fc914-fb83-4fb7-98b4-bcf0c670ccf9",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7920f0b-b6d4-4d98-a6de-afdb077dd40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 19:03:04 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-26 19:03:04 INFO: Use device: cpu\n",
      "2022-07-26 19:03:04 INFO: Loading: tokenize\n",
      "2022-07-26 19:03:04 INFO: Loading: pos\n",
      "2022-07-26 19:03:04 INFO: Loading: lemma\n",
      "2022-07-26 19:03:04 INFO: Loading: depparse\n",
      "2022-07-26 19:03:05 INFO: Loading: sentiment\n",
      "2022-07-26 19:03:05 INFO: Loading: ner\n",
      "2022-07-26 19:03:06 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# sentiment analysis\n",
    "\n",
    "# define pipeline with stanza\n",
    "nlp = stanza.Pipeline('en')\n",
    "\n",
    "# extract sentiments \n",
    "sentence = []\n",
    "sentiment = []\n",
    "\n",
    "doc = nlp(joined_instances)\n",
    "for sent in doc.sentences:\n",
    "    sentence.append(sent.text)\n",
    "    sentiment.append(sent.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a4f5b15-9c85-4baf-8472-6c7ae1d7e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put results in dataframe \n",
    "\n",
    "sentiment_freq = Counter(list(sentiment))\n",
    "\n",
    "keys = ['neutral', 'negative', 'positive']\n",
    "vals = list(sentiment_freq.values())\n",
    "d = {'sentiment': keys, 'count': vals}\n",
    "sentiment_df = pd.DataFrame(d)\n",
    "\n",
    "# save dataframe to file for visualization\n",
    "sentiment_df.to_excel(\"data/sentiment_frequency.xlsx\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2338943-9607-47f8-ae51-a0ec3ce2fb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you please send us a private message , so ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please send me a private message so that I can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Would you like me to email you a copy of one s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>. @Ask_Spectrum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The correct way to do it is via an OCS Account...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The information pertaining to the account assu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This does need to be done at a local outlet wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://t.co/P7XCmTzPQj . actually that 's a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My apologies for any frustrations or inconveni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment\n",
       "0                                            @115712          1\n",
       "1  Can you please send us a private message , so ...          1\n",
       "2  Please send me a private message so that I can...          0\n",
       "3  Would you like me to email you a copy of one s...          0\n",
       "4                                    . @Ask_Spectrum          1\n",
       "5  The correct way to do it is via an OCS Account...          0\n",
       "6  The information pertaining to the account assu...          1\n",
       "7  This does need to be done at a local outlet wi...          1\n",
       "8  https://t.co/P7XCmTzPQj . actually that 's a b...          1\n",
       "9  My apologies for any frustrations or inconveni...          0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display sentiment dataframe for manual inspection\n",
    "d = {'sentence': sentence, 'sentiment': sentiment}\n",
    "df = pd.DataFrame(d)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34421516-4f71-4b32-9e75-3d152b40624a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20e3f4-255e-4c5a-9c4c-46b301435f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
