{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "7a635c9a-8ff3-4b94-8c06-a6c259aa1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8835124-f838-435c-a2b3-306d3a4f8748",
   "metadata": {},
   "source": [
    "## Loading the file\n",
    "\n",
    "Here I open the dataframe created in the preprocessing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "0de7a1b1-30f1-45c1-8259-ef887c5da8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open cleaned dataframe\n",
    "\n",
    "path = \"data/cleaned_customer_dataframe.csv\"\n",
    "filtered_df = pd.read_csv(path)\n",
    "\n",
    "# extract clean sents for bert and raw sents for evaluation\n",
    "raw = filtered_df['raw_sentences'].tolist()\n",
    "clean = filtered_df['sentences'].tolist()\n",
    "\n",
    "# remove NaN instances from both sent lists\n",
    "raw_sents = []\n",
    "clean_sents = []\n",
    "\n",
    "i = 0\n",
    "for item in clean: \n",
    "    if isinstance(item, str) == True and len(item) > 5:\n",
    "        clean_sents.append(item)\n",
    "        raw_sents.append(raw[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "35758326-04a2-4252-9e48-b445db537b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['correct way ocs account takeover email consent form need local office ',\n",
       " 'friend internet need play videogame skill diminish moment internetz ',\n",
       " 'phone number email   ',\n",
       " 'equipment service ',\n",
       " 'literally try pay find   ',\n",
       " 'thank resolve issue quickly   ',\n",
       " 'y all good   fanforlife ',\n",
       " 'frustrated order dinner saturday app ',\n",
       " 'order wrong charge credit card twice ',\n",
       " 'pretty explain issue quote tweet   drag image canvas long center snap ']"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview sentences\n",
    "clean_sents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10b8e3-723b-427b-90f4-f0477a121f77",
   "metadata": {},
   "source": [
    "# Sentence vectors with BERT\n",
    "\n",
    "Here I create sentence vectors with BERT's built-in tokenizer and vectorizer functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "bfec91a6-512e-4780-ba32-9aae42825bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Initialize bert\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "46ab6557-7d46-47e9-9eea-386d5f4aab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize data\n",
    "\n",
    "vectors = []\n",
    "for sent in clean_sents:\n",
    "    tokens = tokenizer.encode(sent, add_special_tokens=True)\n",
    "#     print([tokenizer.decode([token]) for token in tokens])\n",
    "    model.eval()  # turn off dropout layers\n",
    "    tokens_tensor = torch.tensor(tokens).unsqueeze(0)\n",
    "    output = model(tokens_tensor)\n",
    "    vector = output[0].detach().numpy()[0]\n",
    "    vectors.append(vector)\n",
    "#     print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "e70f6f10-9a3a-45c8-a1bd-9881e9f09034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999994 0.67447144 0.5205359  ... 0.81180084 0.5860615  0.6518429 ]\n",
      " [0.67447144 1.         0.44003856 ... 0.7094057  0.5768237  0.61316013]\n",
      " [0.5205359  0.44003856 1.0000001  ... 0.59455526 0.4362641  0.53515774]\n",
      " ...\n",
      " [0.81180084 0.7094057  0.59455526 ... 0.9999999  0.607898   0.75644267]\n",
      " [0.5860615  0.5768237  0.4362641  ... 0.607898   1.0000001  0.6873381 ]\n",
      " [0.6518429  0.61316013 0.53515774 ... 0.75644267 0.6873381  1.0000002 ]]\n"
     ]
    }
   ],
   "source": [
    "# average token vectors into sentence vectors and compute pairwise cosine similarity\n",
    "\n",
    "sentence_vectors = []\n",
    "for vec in vectors: \n",
    "    token_vec = vec[1:-1]\n",
    "    sentence_vec = np.mean(token_vec, axis=0)\n",
    "    sentence_vectors.append(sentence_vec)\n",
    "    \n",
    "similarity_matrix = cosine_similarity(np.asarray(sentence_vectors))\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d448cb-2d8d-453d-8c30-adc72ba4dc9e",
   "metadata": {},
   "source": [
    "# Clustering with KMeans algorithm\n",
    "\n",
    "Here I cluster the sentences based on cosine similarity. Cluster statistics are printed and the 10 best clusters are saved to a csv for further inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "36585e0c-7592-496b-9677-2b14e015d203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette values:\n",
      "Cluster 44: Size:18 | Avg:0.92 | Min:0.22 | Max: 0.96\n",
      "Cluster 3: Size:14 | Avg:0.50 | Min:0.10 | Max: 0.66\n",
      "Cluster 16: Size:8 | Avg:0.26 | Min:0.06 | Max: 0.40\n",
      "Cluster 2: Size:20 | Avg:0.22 | Min:0.02 | Max: 0.39\n",
      "Cluster 47: Size:33 | Avg:0.22 | Min:0.03 | Max: 0.39\n",
      "Cluster 31: Size:8 | Avg:0.21 | Min:-0.00 | Max: 0.32\n",
      "Cluster 25: Size:19 | Avg:0.18 | Min:-0.01 | Max: 0.34\n",
      "Cluster 23: Size:8 | Avg:0.14 | Min:0.02 | Max: 0.27\n",
      "Cluster 43: Size:15 | Avg:0.13 | Min:-0.08 | Max: 0.34\n",
      "Cluster 15: Size:9 | Avg:0.13 | Min:-0.00 | Max: 0.31\n",
      "Cluster 46: Size:19 | Avg:0.12 | Min:0.02 | Max: 0.23\n",
      "Cluster 38: Size:15 | Avg:0.12 | Min:0.04 | Max: 0.20\n",
      "Cluster 5: Size:26 | Avg:0.12 | Min:-0.01 | Max: 0.28\n",
      "Cluster 29: Size:36 | Avg:0.12 | Min:0.03 | Max: 0.25\n",
      "Cluster 7: Size:59 | Avg:0.10 | Min:0.00 | Max: 0.24\n",
      "Cluster 36: Size:12 | Avg:0.10 | Min:-0.05 | Max: 0.30\n",
      "Cluster 24: Size:45 | Avg:0.10 | Min:-0.01 | Max: 0.25\n",
      "Cluster 9: Size:28 | Avg:0.09 | Min:-0.02 | Max: 0.21\n",
      "Cluster 42: Size:17 | Avg:0.09 | Min:-0.05 | Max: 0.26\n",
      "Cluster 49: Size:32 | Avg:0.09 | Min:0.00 | Max: 0.20\n",
      "Cluster 48: Size:32 | Avg:0.09 | Min:-0.02 | Max: 0.27\n",
      "Cluster 0: Size:30 | Avg:0.09 | Min:-0.04 | Max: 0.21\n",
      "Cluster 13: Size:44 | Avg:0.09 | Min:-0.00 | Max: 0.24\n",
      "Cluster 14: Size:36 | Avg:0.09 | Min:-0.01 | Max: 0.23\n",
      "Cluster 32: Size:41 | Avg:0.09 | Min:-0.00 | Max: 0.22\n",
      "Cluster 27: Size:36 | Avg:0.09 | Min:0.01 | Max: 0.21\n",
      "Cluster 10: Size:39 | Avg:0.08 | Min:-0.01 | Max: 0.23\n",
      "Cluster 12: Size:45 | Avg:0.08 | Min:-0.03 | Max: 0.22\n",
      "Cluster 18: Size:46 | Avg:0.08 | Min:-0.00 | Max: 0.23\n",
      "Cluster 11: Size:25 | Avg:0.08 | Min:-0.07 | Max: 0.17\n",
      "Cluster 35: Size:25 | Avg:0.07 | Min:-0.06 | Max: 0.18\n",
      "Cluster 45: Size:23 | Avg:0.07 | Min:-0.02 | Max: 0.20\n",
      "Cluster 30: Size:41 | Avg:0.07 | Min:-0.02 | Max: 0.21\n",
      "Cluster 17: Size:47 | Avg:0.07 | Min:-0.03 | Max: 0.17\n",
      "Cluster 8: Size:34 | Avg:0.07 | Min:-0.01 | Max: 0.14\n",
      "Cluster 33: Size:12 | Avg:0.07 | Min:-0.01 | Max: 0.15\n",
      "Cluster 40: Size:24 | Avg:0.06 | Min:-0.03 | Max: 0.21\n",
      "Cluster 19: Size:35 | Avg:0.06 | Min:-0.03 | Max: 0.21\n",
      "Cluster 34: Size:37 | Avg:0.06 | Min:-0.02 | Max: 0.17\n",
      "Cluster 39: Size:27 | Avg:0.06 | Min:-0.05 | Max: 0.20\n",
      "Cluster 4: Size:38 | Avg:0.06 | Min:-0.08 | Max: 0.24\n",
      "Cluster 21: Size:38 | Avg:0.06 | Min:-0.04 | Max: 0.19\n",
      "Cluster 28: Size:40 | Avg:0.05 | Min:-0.04 | Max: 0.15\n",
      "Cluster 22: Size:32 | Avg:0.05 | Min:-0.11 | Max: 0.17\n",
      "Cluster 1: Size:43 | Avg:0.04 | Min:-0.04 | Max: 0.17\n",
      "Cluster 41: Size:33 | Avg:0.04 | Min:-0.05 | Max: 0.19\n",
      "Cluster 37: Size:32 | Avg:0.03 | Min:-0.05 | Max: 0.13\n",
      "Cluster 26: Size:22 | Avg:0.03 | Min:-0.07 | Max: 0.13\n",
      "Cluster 6: Size:17 | Avg:0.03 | Min:-0.07 | Max: 0.12\n",
      "Cluster 20: Size:28 | Avg:0.02 | Min:-0.05 | Max: 0.15\n"
     ]
    }
   ],
   "source": [
    "# cluster with KMeans\n",
    "\n",
    "# fit and predict clusters\n",
    "num_clusters = 50\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(similarity_matrix)\n",
    "\n",
    "# print cluster statistics\n",
    "sample_silhouette_values = silhouette_samples(similarity_matrix, km.labels_)\n",
    "print(f\"Silhouette values:\")\n",
    "\n",
    "silhouette_values = []\n",
    "for i in range(num_clusters):\n",
    "    cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "    silhouette_values.append((i, cluster_silhouette_values.shape[0], cluster_silhouette_values.mean(), cluster_silhouette_values.min(), cluster_silhouette_values.max(),))\n",
    "    \n",
    "silhouette_values = sorted(silhouette_values, key=lambda tup: tup[2], reverse=True)\n",
    "for s in silhouette_values:\n",
    "    print(f\"Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "9356d7f0-de6f-4af3-86e8-dc343a848d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_sents</th>\n",
       "      <th>clean_sents</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The correct way to do it is via an OCS Account...</td>\n",
       "      <td>correct way ocs account takeover email consent...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My friend is without internet we need to play ...</td>\n",
       "      <td>friend internet need play videogame skill dimi...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have my phone number and email , that 's it .</td>\n",
       "      <td>phone number email</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did I get equipment and service ?</td>\n",
       "      <td>equipment service</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I 'm literally trying to pay and nobody can fi...</td>\n",
       "      <td>literally try pay find</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you for resolving my issue so quickly ! !</td>\n",
       "      <td>thank resolve issue quickly</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Y‚Äôall are the best ‚ò∫ Ô∏è # fanforlife .</td>\n",
       "      <td>y all good   fanforlife</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>So frustrated with üò° Ordered dinner on Saturda...</td>\n",
       "      <td>frustrated order dinner saturday app</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Order was wrong AND they charged my credit car...</td>\n",
       "      <td>order wrong charge credit card twice</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pretty much explained my issue in the quoted t...</td>\n",
       "      <td>pretty explain issue quote tweet   drag image ...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           raw_sents  \\\n",
       "0  The correct way to do it is via an OCS Account...   \n",
       "1  My friend is without internet we need to play ...   \n",
       "2    I have my phone number and email , that 's it .   \n",
       "3              How did I get equipment and service ?   \n",
       "4  I 'm literally trying to pay and nobody can fi...   \n",
       "5    Thank you for resolving my issue so quickly ! !   \n",
       "6              Y‚Äôall are the best ‚ò∫ Ô∏è # fanforlife .   \n",
       "7  So frustrated with üò° Ordered dinner on Saturda...   \n",
       "8  Order was wrong AND they charged my credit car...   \n",
       "9  Pretty much explained my issue in the quoted t...   \n",
       "\n",
       "                                         clean_sents  cluster  \n",
       "0  correct way ocs account takeover email consent...       24  \n",
       "1  friend internet need play videogame skill dimi...       24  \n",
       "2                              phone number email          23  \n",
       "3                                 equipment service        39  \n",
       "4                          literally try pay find           8  \n",
       "5                     thank resolve issue quickly          34  \n",
       "6                           y all good   fanforlife        42  \n",
       "7              frustrated order dinner saturday app        34  \n",
       "8              order wrong charge credit card twice        37  \n",
       "9  pretty explain issue quote tweet   drag image ...       37  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print full cluster overview\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "clustered_articles ={'raw_sents': raw_sents, 'clean_sents': clean_sents, 'cluster': clusters}\n",
    "overview = pd.DataFrame(clustered_articles)\n",
    "overview.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "3775b539-881a-496a-ad4f-7a3e193c06ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_sents</th>\n",
       "      <th>clean_sents</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>iPhone 7 Plus üòä .</td>\n",
       "      <td>iphone plus</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td># mobile_CareXI</td>\n",
       "      <td>mobilecarexi</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Which I do n't get since I know we have espnew...</td>\n",
       "      <td>know espnew home</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>how is Amazon going to solve this ?</td>\n",
       "      <td>amazon go solve</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td># mobile_CareXI</td>\n",
       "      <td>mobilecarexi</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Now we ca n‚Äôt get the account back on the xbox .</td>\n",
       "      <td>nt account xbox</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>Loosing Photoshop subscription ..</td>\n",
       "      <td>loose photoshop subscription</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>My internet SUCKS ! ! ! !</td>\n",
       "      <td>internet suck</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Internet up and down for days in Texas ..</td>\n",
       "      <td>internet day texas</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>I am watching CBS all access right now .</td>\n",
       "      <td>watch cbs access right</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>Happening on iPhone 7 Plus and iPhone 7 . http...</td>\n",
       "      <td>happen iphone plus iphone</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td># mobile_CareXI</td>\n",
       "      <td>mobilecarexi</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>I have a whole zoo of them on my iPhone and iM...</td>\n",
       "      <td>zoo iphone imac tame</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>iPhone 7 Plus .</td>\n",
       "      <td>iphone plus</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td># mobile_Care .</td>\n",
       "      <td>mobilecare</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>I used my 1 jump to get the iPhone x.</td>\n",
       "      <td>jump iphone x</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>cheating enterprises amazon .</td>\n",
       "      <td>cheat enterprise amazon</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td># mobile_Care .</td>\n",
       "      <td>mobilecare</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>Will I get the iPhone X this Friday ? !</td>\n",
       "      <td>iphone x friday</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              raw_sents  \\\n",
       "38                                    iPhone 7 Plus üòä .   \n",
       "262                                     # mobile_CareXI   \n",
       "401   Which I do n't get since I know we have espnew...   \n",
       "472                 how is Amazon going to solve this ?   \n",
       "532                                     # mobile_CareXI   \n",
       "619    Now we ca n‚Äôt get the account back on the xbox .   \n",
       "709                   Loosing Photoshop subscription ..   \n",
       "723                           My internet SUCKS ! ! ! !   \n",
       "762           Internet up and down for days in Texas ..   \n",
       "817            I am watching CBS all access right now .   \n",
       "858   Happening on iPhone 7 Plus and iPhone 7 . http...   \n",
       "949                                     # mobile_CareXI   \n",
       "1049  I have a whole zoo of them on my iPhone and iM...   \n",
       "1197                                    iPhone 7 Plus .   \n",
       "1208                                    # mobile_Care .   \n",
       "1211              I used my 1 jump to get the iPhone x.   \n",
       "1346                      cheating enterprises amazon .   \n",
       "1379                                    # mobile_Care .   \n",
       "1430            Will I get the iPhone X this Friday ? !   \n",
       "\n",
       "                        clean_sents  cluster  \n",
       "38                     iphone plus        25  \n",
       "262                   mobilecarexi        25  \n",
       "401               know espnew home        25  \n",
       "472                amazon go solve        25  \n",
       "532                   mobilecarexi        25  \n",
       "619                nt account xbox        25  \n",
       "709   loose photoshop subscription        25  \n",
       "723              internet suck            25  \n",
       "762             internet day texas        25  \n",
       "817         watch cbs access right        25  \n",
       "858    happen iphone plus iphone          25  \n",
       "949                   mobilecarexi        25  \n",
       "1049        zoo iphone imac tame          25  \n",
       "1197                   iphone plus        25  \n",
       "1208                    mobilecare        25  \n",
       "1211                 jump iphone x        25  \n",
       "1346       cheat enterprise amazon        25  \n",
       "1379                    mobilecare        25  \n",
       "1430             iphone x friday          25  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print selection of instances per cluster for inspection\n",
    "\n",
    "df = overview.loc[overview['cluster'] == 25]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "00d5f776-5cd9-4d78-82c6-a652e5525bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write clusters to csv file\n",
    "# df.to_excel('results/cluster35providedetailsinvestigate.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
