{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4867d909-559c-4f13-ba0b-8ff48fd49ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shark\\anaconda3\\lib\\site-packages\\spacy\\util.py:758: UserWarning: [W095] Model 'en_core_web_sm' (3.0.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.1.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c81648-3dc5-4f00-9f7c-042849005e31",
   "metadata": {},
   "source": [
    "# Load filtered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "903b1802-c756-4c8a-987a-ce069a84e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open cleaned dataframe\n",
    "\n",
    "path = \"data/cleaned_customer_dataframe.csv\"\n",
    "filtered_df = pd.read_csv(path)\n",
    "\n",
    "# extract clean sents for bert and raw sents for evaluation\n",
    "raw = filtered_df['raw_sentences'].tolist()\n",
    "clean = filtered_df['sentences'].tolist()\n",
    "\n",
    "# remove NaN instances from both sent lists\n",
    "# split sentences into words without losing sentence structure\n",
    "raw_sents = []\n",
    "clean_sents = []\n",
    "\n",
    "i = 0\n",
    "for item in clean: \n",
    "    if isinstance(item, str) == True and len(item) > 5:\n",
    "        item = item.split()\n",
    "        sent = []\n",
    "        for word in item:\n",
    "            sent.append(word)\n",
    "        clean_sents.append(sent)\n",
    "        raw_sents.append(raw[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18afd6b-0eb2-4836-b22a-7410f8a3928b",
   "metadata": {},
   "source": [
    "# Train word2vec model \n",
    "\n",
    "Here I train a word2vec model on the dataset and create sentence vectors by averaging word vectors per sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "201bf41e-0f5d-42ad-85aa-13c6256c0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train w2v model\n",
    "\n",
    "w2v_model = Word2Vec(sentences=clean_sents, vector_size=50, window=4, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f89cbb9f-41cd-458c-a01e-906d30a57d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1443, 50)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "    \n",
    "vectorized_docs = vectorize(clean_sents, model=w2v_model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9497bbe-0b38-47d7-839d-55887d943e72",
   "metadata": {},
   "source": [
    "# Clustering with KMeans\n",
    "\n",
    "Here I cluster the data based on sentence vectors. Cluster statistics and some examples are printed for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cf7c1940-7418-487f-8c19-8820f7679a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette values:\n",
      "Cluster 11: Size:17 | Avg:1.00 | Min:1.00 | Max: 1.00\n",
      "Cluster 14: Size:3 | Avg:1.00 | Min:1.00 | Max: 1.00\n",
      "Cluster 17: Size:2 | Avg:1.00 | Min:1.00 | Max: 1.00\n",
      "Cluster 24: Size:4 | Avg:1.00 | Min:1.00 | Max: 1.00\n",
      "Cluster 28: Size:11 | Avg:0.63 | Min:0.20 | Max: 0.79\n",
      "Cluster 29: Size:3 | Avg:0.58 | Min:0.28 | Max: 0.73\n",
      "Cluster 13: Size:4 | Avg:0.39 | Min:0.18 | Max: 0.59\n",
      "Cluster 7: Size:6 | Avg:0.38 | Min:0.09 | Max: 0.56\n",
      "Cluster 25: Size:10 | Avg:0.31 | Min:0.03 | Max: 0.54\n",
      "Cluster 18: Size:13 | Avg:0.07 | Min:-0.09 | Max: 0.31\n",
      "Cluster 16: Size:176 | Avg:0.07 | Min:0.02 | Max: 0.13\n",
      "Cluster 21: Size:57 | Avg:0.05 | Min:-0.03 | Max: 0.16\n",
      "Cluster 19: Size:113 | Avg:0.04 | Min:-0.03 | Max: 0.14\n",
      "Cluster 23: Size:22 | Avg:0.04 | Min:-0.15 | Max: 0.14\n",
      "Cluster 0: Size:20 | Avg:0.02 | Min:-0.07 | Max: 0.15\n",
      "Cluster 27: Size:52 | Avg:0.02 | Min:-0.07 | Max: 0.12\n",
      "Cluster 20: Size:196 | Avg:0.00 | Min:-0.05 | Max: 0.06\n",
      "Cluster 26: Size:48 | Avg:-0.00 | Min:-0.10 | Max: 0.18\n",
      "Cluster 22: Size:57 | Avg:-0.01 | Min:-0.09 | Max: 0.11\n",
      "Cluster 6: Size:15 | Avg:-0.02 | Min:-0.18 | Max: 0.15\n",
      "Cluster 4: Size:92 | Avg:-0.03 | Min:-0.11 | Max: 0.06\n",
      "Cluster 15: Size:80 | Avg:-0.04 | Min:-0.12 | Max: 0.04\n",
      "Cluster 12: Size:60 | Avg:-0.05 | Min:-0.15 | Max: 0.07\n",
      "Cluster 3: Size:30 | Avg:-0.06 | Min:-0.18 | Max: 0.17\n",
      "Cluster 2: Size:72 | Avg:-0.06 | Min:-0.14 | Max: 0.04\n",
      "Cluster 10: Size:76 | Avg:-0.08 | Min:-0.19 | Max: 0.04\n",
      "Cluster 5: Size:25 | Avg:-0.08 | Min:-0.18 | Max: 0.05\n",
      "Cluster 8: Size:19 | Avg:-0.08 | Min:-0.18 | Max: 0.03\n",
      "Cluster 1: Size:53 | Avg:-0.12 | Min:-0.26 | Max: -0.02\n",
      "Cluster 9: Size:107 | Avg:-0.16 | Min:-0.30 | Max: -0.05\n"
     ]
    }
   ],
   "source": [
    "# cluster with KMeans\n",
    "\n",
    "# fit and predict clusters\n",
    "num_clusters = 30\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(vectorized_docs)\n",
    "\n",
    "# print cluster statistics\n",
    "sample_silhouette_values = silhouette_samples(vectorized_docs, km.labels_)\n",
    "print(f\"Silhouette values:\")\n",
    "\n",
    "silhouette_values = []\n",
    "for i in range(num_clusters):\n",
    "    cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "    silhouette_values.append((i, cluster_silhouette_values.shape[0], cluster_silhouette_values.mean(), cluster_silhouette_values.min(), cluster_silhouette_values.max(),))\n",
    "    \n",
    "silhouette_values = sorted(silhouette_values, key=lambda tup: tup[2], reverse=True)\n",
    "for s in silhouette_values:\n",
    "    print(f\"Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "de63961b-5aa4-48a7-88db-a30ab45a620f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_sents</th>\n",
       "      <th>clean_sents</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The correct way to do it is via an OCS Account...</td>\n",
       "      <td>[correct, way, ocs, account, takeover, email, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My friend is without internet we need to play ...</td>\n",
       "      <td>[friend, internet, need, play, videogame, skil...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have my phone number and email , that 's it .</td>\n",
       "      <td>[phone, number, email]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did I get equipment and service ?</td>\n",
       "      <td>[equipment, service]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I 'm literally trying to pay and nobody can fi...</td>\n",
       "      <td>[literally, try, pay, find]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you for resolving my issue so quickly ! !</td>\n",
       "      <td>[thank, resolve, issue, quickly]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Y‚Äôall are the best ‚ò∫ Ô∏è # fanforlife .</td>\n",
       "      <td>[y, all, good, fanforlife]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>So frustrated with üò° Ordered dinner on Saturda...</td>\n",
       "      <td>[frustrated, order, dinner, saturday, app]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Order was wrong AND they charged my credit car...</td>\n",
       "      <td>[order, wrong, charge, credit, card, twice]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pretty much explained my issue in the quoted t...</td>\n",
       "      <td>[pretty, explain, issue, quote, tweet, drag, i...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           raw_sents  \\\n",
       "0  The correct way to do it is via an OCS Account...   \n",
       "1  My friend is without internet we need to play ...   \n",
       "2    I have my phone number and email , that 's it .   \n",
       "3              How did I get equipment and service ?   \n",
       "4  I 'm literally trying to pay and nobody can fi...   \n",
       "5    Thank you for resolving my issue so quickly ! !   \n",
       "6              Y‚Äôall are the best ‚ò∫ Ô∏è # fanforlife .   \n",
       "7  So frustrated with üò° Ordered dinner on Saturda...   \n",
       "8  Order was wrong AND they charged my credit car...   \n",
       "9  Pretty much explained my issue in the quoted t...   \n",
       "\n",
       "                                         clean_sents  cluster  \n",
       "0  [correct, way, ocs, account, takeover, email, ...       20  \n",
       "1  [friend, internet, need, play, videogame, skil...       20  \n",
       "2                             [phone, number, email]       12  \n",
       "3                               [equipment, service]       12  \n",
       "4                        [literally, try, pay, find]       16  \n",
       "5                   [thank, resolve, issue, quickly]       23  \n",
       "6                         [y, all, good, fanforlife]        2  \n",
       "7         [frustrated, order, dinner, saturday, app]        5  \n",
       "8        [order, wrong, charge, credit, card, twice]        2  \n",
       "9  [pretty, explain, issue, quote, tweet, drag, i...        9  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print full cluster overview\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "clustered_articles ={'raw_sents': raw_sents, 'clean_sents':clean_sents, 'cluster': clusters}\n",
    "overview = pd.DataFrame(clustered_articles)\n",
    "overview.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f395d48e-b394-4ef5-85b0-2b162b4eb67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_sents</th>\n",
       "      <th>clean_sents</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>No refund because it \" does n't qualify \" .</td>\n",
       "      <td>[refund, qualify]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>and so you have provided me the refund for that .</td>\n",
       "      <td>[provide, refund]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>I would like a refund .</td>\n",
       "      <td>[like, refund]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Give me my refund</td>\n",
       "      <td>[refund]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Can you refund me the difference ? .</td>\n",
       "      <td>[refund, difference]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>i 'd like a full refund 1/2 .</td>\n",
       "      <td>[like, refund]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Can I get a refund ? .</td>\n",
       "      <td>[refund]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td># refund https://t.co/7RoF4wNv9v .</td>\n",
       "      <td>[refund]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>A refund .</td>\n",
       "      <td>[refund]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>How can I get a refund for food that I do n't ...</td>\n",
       "      <td>[refund, food, like]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              raw_sents           clean_sents  \\\n",
       "69          No refund because it \" does n't qualify \" .     [refund, qualify]   \n",
       "114   and so you have provided me the refund for that .     [provide, refund]   \n",
       "321                             I would like a refund .        [like, refund]   \n",
       "524                                   Give me my refund              [refund]   \n",
       "607                Can you refund me the difference ? .  [refund, difference]   \n",
       "933                       i 'd like a full refund 1/2 .        [like, refund]   \n",
       "1023                             Can I get a refund ? .              [refund]   \n",
       "1130                 # refund https://t.co/7RoF4wNv9v .              [refund]   \n",
       "1161                                         A refund .              [refund]   \n",
       "1364  How can I get a refund for food that I do n't ...  [refund, food, like]   \n",
       "\n",
       "      cluster  \n",
       "69         25  \n",
       "114        25  \n",
       "321        25  \n",
       "524        25  \n",
       "607        25  \n",
       "933        25  \n",
       "1023       25  \n",
       "1130       25  \n",
       "1161       25  \n",
       "1364       25  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print selection of instances per cluster for inspection\n",
    "\n",
    "df = overview.loc[overview['cluster'] == 25]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a607ed52-9e08-4647-8c34-a4876d96e033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(26, 13), (20, 11), (16, 6), (27, 2), (2, 2)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking in which clusters the keywords can be found\n",
    "\n",
    "df = overview.loc[overview['raw_sents'].str.contains('internet')].head(40)\n",
    "l = df['cluster'].tolist()\n",
    "\n",
    "from collections import Counter\n",
    "c = Counter(list(l))\n",
    "c.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "10c4e405-bcec-4530-8844-93d5e06ff19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save chosen cluster to excel for further inspection\n",
    "# df.to_excel('results/cluster26orderproblems.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb08da0-aec4-4736-ae15-1bc8a84340cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
